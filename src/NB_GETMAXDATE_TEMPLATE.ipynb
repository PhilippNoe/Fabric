{"cells":[{"cell_type":"markdown","source":["Generalized Get Max Timestamp Notebook\n","=======================================\n","Retrieves maximum timestamp from any table/column configuration.\n","\n","Prerequsite: The lakehouse which holds the targeted table must be set as default lakehouse for this notebook\n","\n","Parameter: \n","- table_name: Table name (required)\n","- date_column: Date/datetime column name (required) \n","- time_column: Optional separate time column (default: None)\n","- output_format: Output format (default: \"%Y-%m-%d %H:%M:%S\")"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"70e5c7b8-bd98-46ae-b298-6c7e8c6f197f"},{"cell_type":"code","source":["# =============================================================================\n","# PARAMETERS\n","# =============================================================================\n","table_name = \"\"\n","date_column = \"\"\n","time_column = None\n","output_format = \"%Y-%m-%d %H:%M:%S\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"5db2e9eb-388c-416a-ada3-77544bdbf74f","normalized_state":"finished","queued_time":"2025-11-17T14:56:25.0731563Z","session_start_time":"2025-11-17T14:56:25.0741456Z","execution_start_time":"2025-11-17T14:56:39.3483921Z","execution_finish_time":"2025-11-17T14:56:39.7728269Z","parent_msg_id":"0299a242-236e-4e85-b38c-92170eccb2ea"},"text/plain":"StatementMeta(, 5db2e9eb-388c-416a-ada3-77544bdbf74f, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"91918def-ee68-477b-a594-e3ddb995a1d6"},{"cell_type":"code","source":["#TEST\n","table_name = \"BELEG\"\n","date_column = \"BearbeitetAm\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"5db2e9eb-388c-416a-ada3-77544bdbf74f","normalized_state":"finished","queued_time":"2025-11-17T14:57:54.1028462Z","session_start_time":null,"execution_start_time":"2025-11-17T14:57:54.1039407Z","execution_finish_time":"2025-11-17T14:57:54.4639301Z","parent_msg_id":"28b58849-09ff-4b14-8851-ac77417e30a6"},"text/plain":"StatementMeta(, 5db2e9eb-388c-416a-ada3-77544bdbf74f, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"editable":false,"run_control":{"frozen":true}},"id":"f18f4432-140b-40dc-bd37-c3fbb220f8ef"},{"cell_type":"code","source":["# =============================================================================\n","# IMPORTS & SPARK CONFIG\n","# =============================================================================\n","from pyspark.sql import functions as F\n","from notebookutils import mssparkutils\n","from datetime import datetime, date\n","\n","# Parquet datetime handling\n","spark.conf.set(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\n","spark.conf.set(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\")\n","spark.conf.set(\"spark.sql.legacy.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\n","spark.conf.set(\"spark.sql.legacy.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"5db2e9eb-388c-416a-ada3-77544bdbf74f","normalized_state":"finished","queued_time":"2025-11-17T14:56:25.0777769Z","session_start_time":null,"execution_start_time":"2025-11-17T14:56:39.7748872Z","execution_finish_time":"2025-11-17T14:56:40.0962444Z","parent_msg_id":"4373668b-8f21-471f-a0a6-fa96b9c93c49"},"text/plain":"StatementMeta(, 5db2e9eb-388c-416a-ada3-77544bdbf74f, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d6d6e76-da06-4a59-b8f9-e3e9f3e4c29e"},{"cell_type":"markdown","source":["Description of the function below:\n","\n","    Retrieves the maximum timestamp from a table.\n","    \n","    Args:\n","        table_name: Name of the table\n","        date_column: Name of the date/datetime column\n","        time_column: Optional name of separate time column\n","        output_format: strftime format string for output\n","        \n","    Returns:\n","        str: Formatted maximum timestamp, or empty string if no data\n","        \n","    Raises:\n","        ValueError: If parameters are invalid or columns don't exist\n","        RuntimeError: If table loading or processing fails"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5c8e5854-828d-4b1a-804c-bc5f6f5eda2f"},{"cell_type":"code","source":["# =============================================================================\n","# MAIN LOGIC\n","# =============================================================================\n","def get_max_timestamp(table_name, date_column, time_column, output_format):\n","\n","    # Validate inputs\n","    if not table_name or not date_column:\n","        raise ValueError(\"table_name and date_column are required\")\n","    \n","    # Load table\n","    try:\n","        df = spark.read.table(table_name)\n","    except Exception as e:\n","        raise RuntimeError(f\"Failed to load table '{table_name}': {str(e)}\")\n","    \n","    # Return empty string if table is empty\n","    if df.rdd.isEmpty():\n","        return \"\"\n","    \n","    # Process based on column configuration\n","    if time_column:\n","        # Separate date + time columns\n","        if date_column not in df.columns or time_column not in df.columns:\n","            raise ValueError(\n","                f\"Required columns not found. \"\n","                f\"Needed: [{date_column}, {time_column}]. \"\n","                f\"Available: {df.columns}\"\n","            )\n","        \n","        max_ts = (\n","            df.withColumn(\n","                \"_ts\",\n","                F.to_timestamp(\n","                    F.concat_ws(\" \",\n","                        F.date_format(F.col(date_column), \"yyyy-MM-dd\"),\n","                        F.col(time_column).cast(\"string\")\n","                    ),\n","                    \"yyyy-MM-dd HH:mm:ss\"\n","                )\n","            )\n","            .select(F.max(\"_ts\"))\n","            .collect()[0][0]\n","        )\n","    else:\n","        # Single datetime/date column\n","        if date_column not in df.columns:\n","            raise ValueError(\n","                f\"Column '{date_column}' not found. \"\n","                f\"Available: {df.columns}\"\n","            )\n","        \n","        max_ts = df.select(F.max(date_column)).collect()[0][0]\n","    \n","    # Format and return\n","    if max_ts is None:\n","        return \"\"\n","    elif isinstance(max_ts, datetime):\n","        return max_ts.strftime(output_format)\n","    elif isinstance(max_ts, date):\n","        return datetime.combine(max_ts, datetime.min.time()).strftime(output_format)\n","    else:\n","        return str(max_ts)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"5db2e9eb-388c-416a-ada3-77544bdbf74f","normalized_state":"finished","queued_time":"2025-11-17T14:56:50.4278296Z","session_start_time":null,"execution_start_time":"2025-11-17T14:56:50.4291891Z","execution_finish_time":"2025-11-17T14:56:50.7825536Z","parent_msg_id":"b92b23ba-ef55-4f0c-8fe0-89da061cb82b"},"text/plain":"StatementMeta(, 5db2e9eb-388c-416a-ada3-77544bdbf74f, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"be0aba44-7abc-47fb-a3e3-b9286e8e36c3"},{"cell_type":"code","source":["# =============================================================================\n","# EXECUTION\n","# =============================================================================\n","latest_timestamp_str = get_max_timestamp(table_name, date_column, time_column, output_format)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"5db2e9eb-388c-416a-ada3-77544bdbf74f","normalized_state":"finished","queued_time":"2025-11-17T14:58:02.2536936Z","session_start_time":null,"execution_start_time":"2025-11-17T14:58:02.2549999Z","execution_finish_time":"2025-11-17T14:58:05.7338181Z","parent_msg_id":"d73a9265-8bbf-479e-a882-5f27b4805755"},"text/plain":"StatementMeta(, 5db2e9eb-388c-416a-ada3-77544bdbf74f, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"99320bc8-7570-4399-a1db-e6f5be4f13ef"},{"cell_type":"code","source":["# =============================================================================\n","# RETURN TO PIPELINE\n","# =============================================================================\n","mssparkutils.notebook.exit(latest_timestamp_str)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"5db2e9eb-388c-416a-ada3-77544bdbf74f","normalized_state":"finished","queued_time":"2025-11-17T14:58:09.6918598Z","session_start_time":null,"execution_start_time":"2025-11-17T14:58:09.6929594Z","execution_finish_time":"2025-11-17T14:58:10.0005593Z","parent_msg_id":"8119fa2e-e777-49c0-a099-c438da09fd68"},"text/plain":"StatementMeta(, 5db2e9eb-388c-416a-ada3-77544bdbf74f, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ExitValue: 2025-11-14 12:57:37"]}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5a1db90f-e191-4d2c-a8bc-04a779709fa2"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"4b75b6d7-f6d2-4132-97f2-890a81849cc8"}],"default_lakehouse":"4b75b6d7-f6d2-4132-97f2-890a81849cc8","default_lakehouse_name":"LH_Bronze_SelectLine","default_lakehouse_workspace_id":"2137d170-8585-45ee-8e6b-6e208904a512"}}},"nbformat":4,"nbformat_minor":5}
